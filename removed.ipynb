{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called 'df' with a column 'side' indicating the side of the game (e.g., 'blue' or 'red')\n",
    "# and a column 'result' indicating the result of the game (1=win, 0=loss)\n",
    "\n",
    "# Calculate the total number of games for each side\n",
    "total_games = df_objectives.groupby('side').size()\n",
    "\n",
    "# Calculate the number of wins for each side\n",
    "wins = df_objectives[df_objectives['result'] == 1].groupby('side').size()\n",
    "\n",
    "# Calculate the win percentage for each side\n",
    "win_percentage = (wins / total_games) * 100\n",
    "\n",
    "# Print the win percentage for each side\n",
    "print(win_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat_all = df.corr(numeric_only=True)\n",
    "\n",
    "sns.heatmap(corrmat_all, vmax=.8, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the column of interest\n",
    "column_name = 'result'  # Replace 'results' with the actual column name\n",
    "correlation_values = corrmat_all[column_name]\n",
    "\n",
    "# Sort the correlation values in descending order\n",
    "sorted_correlation_values = correlation_values.sort_values(ascending=False)\n",
    "\n",
    "# Print the sorted correlation values\n",
    "print(sorted_correlation_values.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is not strongly correlated except between energy and loudness, which makes sense. \n",
    "# Popularity has a correspondence to release data, which also makes sense, as more recent songs are probably more popular. \n",
    "# Length and energy seem to have a correlation - perhaps shorter songs are more energetic?\n",
    "corrmat = df_objectives.corr(numeric_only=True)\n",
    "# f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Show the joint distribution using kernel density estimation\n",
    "g = sns.jointplot(\n",
    "    data=df_objectives,\n",
    "    x=\"turretplates\", y=\"golddiffat15\", hue=\"result\",\n",
    "    kind=\"kde\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Show the joint distribution using kernel density estimation\n",
    "g = sns.jointplot(\n",
    "    data=df_objectives,\n",
    "    x=\"kills\", y=\"damagetochampions\", hue=\"result\",\n",
    "    kind=\"kde\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans and build a model\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42, n_init='auto')\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Use that model to decide, using the Elbow Method, the best number of clusters to build\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x=range(1, 11), y=wcss,marker='o',color='red')\n",
    "plt.title('Elbow')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 3, n_init='auto', init = 'k-means++')\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"lightblue\")\n",
    "plt.scatter(df_objectives['kills'],df_objectives['damagetochampions'],c = labels)\n",
    "plt.xlabel('Kills')\n",
    "plt.ylabel('Damage Dealt to Champions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "correct_labels = sum(y == labels)\n",
    "\n",
    "print(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, y.size))\n",
    "print('Accuracy score: {0:0.3f}'. format(correct_labels/float(y.size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 2, n_init='auto', init = 'k-means++')\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"lightblue\")\n",
    "plt.scatter(df_objectives['golddiffat15'],df_objectives['turretplates'],c = labels)\n",
    "plt.xlabel('Kills')\n",
    "plt.ylabel('Damage Dealt to Champions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "correct_labels = sum(y == labels)\n",
    "\n",
    "print(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, y.size))\n",
    "print('Accuracy score: {0:0.3f}'. format(correct_labels/float(y.size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_objectives.plot.scatter('turretplates','golddiffat15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from common.utils import load_data, mape\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "np.set_printoptions(precision=2)\n",
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_times.plot(y='gamelength', subplots=True, figsize=(15, 8), fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Game Length', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets, note the strong seasonal component in the data\n",
    "train_start_dt = '2023-10-01 19:59:21'\n",
    "test_start_dt = '2023-11-10 00:00:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the differences\n",
    "df_times[(df_times.index < test_start_dt) & (df_times.index >= train_start_dt)][['gamelength']].rename(columns={'gamelength':'train'}) \\\n",
    "    .join(df_times[test_start_dt:][['gamelength']].rename(columns={'gamelength':'test'}), how='outer') \\\n",
    "    .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('gamelength', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_times.copy()[(df_times.index >= train_start_dt) & (df_times.index < test_start_dt)][['gamelength']]\n",
    "test = df_times.copy()[df_times.index >= test_start_dt][['gamelength']]\n",
    "\n",
    "print('Training data shape: ', train.shape)\n",
    "print('Test data shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "scaler = MinMaxScaler()\n",
    "train['gamelength'] = scaler.fit_transform(train)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale also the test data\n",
    "test['gamelength'] = scaler.transform(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizon value: 3 hours, i.e., the number of steps to forecast ahead\n",
    "HORIZON = 3\n",
    "\n",
    "order = (4, 1, 0)\n",
    "seasonal_order = (1, 1, 0, 24)\n",
    "\n",
    "model = SARIMAX(endog=train, order=order, seasonal_order=seasonal_order)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_shifted = test.copy()\n",
    "\n",
    "HORIZON = 3  # Replace this with your actual HORIZON value\n",
    "\n",
    "for t in range(1, HORIZON):\n",
    "    test_shifted['gamelength+' + str(t)] = test_shifted['gamelength'].shift(-t)\n",
    "\n",
    "test_shifted = test_shifted.dropna(how='any')\n",
    "print(test_shifted.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above, the data is shifted horizontally according to its horizon point.\n",
    "# Make predictions on your test data using this sliding window approach in a loop the size of the test data length:\n",
    "# NOTE: Execution time was about 2.8 mins in my computer: 169.315 seconds. Both VSCode and Colab measure the execution time.\n",
    "# Skipping %% time because it is not supported in VSCode. And silencing SARIMAX fit to avoid printing the model fit details.\n",
    "#\n",
    "# Should conclude in 46 iterations.\n",
    "\n",
    "training_window = 720 # dedicate 30 days (720 hours) for training\n",
    "train_ts = train['gamelength']\n",
    "test_ts = test_shifted\n",
    "\n",
    "history = [x for x in train_ts]\n",
    "history = history[(-training_window):]\n",
    "\n",
    "predictions = list()\n",
    "\n",
    "order = (2, 1, 0)\n",
    "seasonal_order = (1, 1, 0, 24)\n",
    "\n",
    "\n",
    "for t in range(test_ts.shape[0]):\n",
    "    model = SARIMAX(endog=history, order=order, seasonal_order=seasonal_order)\n",
    "    # Silence\n",
    "    model_fit = model.fit(disp=False)\n",
    "    yhat = model_fit.forecast(steps = HORIZON)\n",
    "    predictions.append(yhat)\n",
    "    obs = list(test_ts.iloc[t])\n",
    "    # move the training window\n",
    "    history.append(obs[0])\n",
    "    history.pop(0)\n",
    "    print(test_ts.index[t])\n",
    "    print(t+1, ': predicted =', yhat, 'expected =', obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(predictions, columns=['t+'+str(t) for t in range(1, HORIZON+1)])\n",
    "eval_df['timestamp'] = test.index[0:len(test.index)-HORIZON+1]\n",
    "eval_df = pd.melt(eval_df, id_vars='timestamp', value_name='prediction', var_name='h')\n",
    "eval_df['actual'] = np.array(np.transpose(test_ts)).ravel()\n",
    "eval_df[['prediction', 'actual']] = scaler.inverse_transform(eval_df[['prediction', 'actual']])\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "if(HORIZON > 1):\n",
    "    eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']\n",
    "    print(eval_df.groupby('h')['APE'].mean())\n",
    "\n",
    "# calculate one step's MAPE\n",
    "print('One step forecast MAPE: ', (mean_absolute_percentage_error(eval_df[eval_df['h'] == 't+1']['prediction'], eval_df[eval_df['h'] == 't+1']['actual']))*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the multi-step forecast MAPE:\n",
    "\n",
    "print('Multi-step forecast MAPE: ', mean_absolute_percentage_error(eval_df['prediction'], eval_df['actual'])*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the accuracy measurement visually, with a plot\n",
    "\n",
    "if(HORIZON == 1):\n",
    "    ## Plotting single step forecast\n",
    "    eval_df.plot(x='timestamp', y=['actual', 'prediction'], style=['r', 'b'], figsize=(15, 8))\n",
    "\n",
    "else:\n",
    "    ## Plotting multi step forecast\n",
    "    plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]\n",
    "    for t in range(1, HORIZON+1):\n",
    "        plot_df['t+'+str(t)] = eval_df[(eval_df.h=='t+'+str(t))]['prediction'].values\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(plot_df['timestamp'], plot_df['actual'], color='red',linewidth=2, label='actual')\n",
    "    for t in range(1, HORIZON+1):\n",
    "        x = plot_df['timestamp'][(t-1):]\n",
    "        y = plot_df['t+'+str(t)][0:len(x)]\n",
    "        ax.plot(x, y, color='blue', linewidth=2*math.pow(.9,t),alpha=math.pow(0.6,t), label='t+'+str(t))\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "plt.xlabel('timestamp', fontsize=12)\n",
    "plt.ylabel('load', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
